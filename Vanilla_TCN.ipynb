{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smBello-tse/TCN/blob/main/Vanilla_TCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6814236b-8ddd-4cd9-ba2d-15f69f3abe57",
      "metadata": {
        "id": "6814236b-8ddd-4cd9-ba2d-15f69f3abe57"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from math import floor\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4597d5b6-21e3-4f0e-b0f7-33b805dd7263",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4597d5b6-21e3-4f0e-b0f7-33b805dd7263",
        "outputId": "c005f4cc-23fe-4fa7-df95-00344cab910d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ],
      "source": [
        "with open(\"shakespeare.txt\", \"r\") as f:\n",
        "    text = f.read()\n",
        "print(text[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "33e739fa-fea1-41aa-82c0-058d8c0f90d2",
      "metadata": {
        "id": "33e739fa-fea1-41aa-82c0-058d8c0f90d2"
      },
      "outputs": [],
      "source": [
        "vocab = list(set(text))\n",
        "vocab.sort()\n",
        "char2id = {vocab[i]: i for i in range(len(vocab))}\n",
        "id2char = {i: vocab[i] for i in range(len(vocab))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2056e648-c73b-4427-958b-17e568f22de4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2056e648-c73b-4427-958b-17e568f22de4",
        "outputId": "a97b06be-092c-4fee-9a1c-a8250d3120e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Richard\n"
          ]
        }
      ],
      "source": [
        "def encode(text):\n",
        "    return [char2id[ch] for ch in text]\n",
        "\n",
        "def decode(ids):\n",
        "    if type(ids) == int: ids = [ids]\n",
        "    return \"\".join([id2char[id] for id in ids])\n",
        "\n",
        "print(decode(encode(\"Richard\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2d326eed-320a-4174-984d-5ce703d63529",
      "metadata": {
        "id": "2d326eed-320a-4174-984d-5ce703d63529"
      },
      "outputs": [],
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, text, context_size):\n",
        "        super(TextDataset, self).__init__()\n",
        "        self.text = text\n",
        "        self.context_size = context_size\n",
        "\n",
        "    def __len__(self):\n",
        "        if len(self.text) % self.context_size == 0: return floor(len(self.text) / self.context_size) * self.context_size\n",
        "        else: return floor(len(self.text) / self.context_size) * self.context_size + len(self.text) % self.context_size - 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        offset = idx % self.context_size\n",
        "        start = idx - offset\n",
        "        window = encode(self.text[start:start + offset + 2])\n",
        "        while len(window) < self.context_size + 1:\n",
        "            window = encode(\".\") + window\n",
        "        return torch.tensor(window[:-1], dtype=torch.long), torch.tensor(window[-1], dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5b2df4b1-2394-4f68-b0e5-9cd6f1232292",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b2df4b1-2394-4f68-b0e5-9cd6f1232292",
        "outputId": "1eed9135-7771-4837-cc98-4d0908059d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n",
            "..........B ---> o\n",
            ".........Bo ---> b\n",
            "........Bob ---> b\n",
            ".......Bobb ---> y\n",
            "......Bobby --->  \n",
            ".....Bobby  ---> i\n",
            "....Bobby i ---> s\n",
            "...Bobby is --->  \n",
            "..Bobby is  ---> n\n",
            ".Bobby is n ---> o\n",
            "Bobby is no ---> t\n",
            "..........t --->  \n",
            ".........t  ---> h\n",
            "........t h ---> e\n",
            ".......t he ---> r\n",
            "......t her ---> e\n",
            ".....t here --->  \n",
            "....t here  ---> t\n",
            "...t here t ---> o\n",
            "..t here to ---> d\n",
            ".t here tod ---> a\n",
            "t here toda ---> y\n"
          ]
        }
      ],
      "source": [
        "dts = TextDataset(\"Bobby is not here today\", 11)\n",
        "print(len(dts))\n",
        "for i in range(len(dts)):\n",
        "    x, y = dts[i]\n",
        "    print(decode(x.tolist()), \"--->\", decode(y.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "55d25e5c-9bf2-42ec-8ebd-a0b859112efa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55d25e5c-9bf2-42ec-8ebd-a0b859112efa",
        "outputId": "2e6be0ec-b6aa-4d2e-d75d-bbead7697803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".........................First C\n"
          ]
        }
      ],
      "source": [
        "context_size = 32 # Increased from 8\n",
        "vocab_size = len(vocab)\n",
        "train_dataset = TextDataset(text, context_size)\n",
        "x, y = train_dataset[6]\n",
        "print(decode(x.tolist()))\n",
        "batch_size = 512\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "fa702fd1-8146-48ae-aecf-7740af7c316f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa702fd1-8146-48ae-aecf-7740af7c316f",
        "outputId": "cd8f010a-afc9-4e04-a7ac-2cbdd3b8a9de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 5])\n",
            "Parameter containing:\n",
            "tensor([[[ 0.4616,  0.2003, -0.0968]]], requires_grad=True)\n",
            "tensor([[[-0.1900,  0.5078,  1.4987,  1.9216,  1.1658]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor(-0.2903, grad_fn=<MulBackward0>)\n",
            "Parameter containing:\n",
            "tensor([0.1003], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "class CausalConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size):\n",
        "        super(CausalConv1d, self).__init__()\n",
        "        self.x_causal_pad = kernel_size - 1\n",
        "        self.causalConv1d = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_pad = nn.functional.pad(x, (self.x_causal_pad, 0), \"constant\", 0.)\n",
        "        return self.causalConv1d(x_pad)\n",
        "\n",
        "\n",
        "x = torch.tensor([[[3., 2., 4., -1., 6.]]])\n",
        "print(x.shape)\n",
        "conv = CausalConv1d(1, 1, 3)\n",
        "print(conv.causalConv1d.weight)\n",
        "print(conv(x))\n",
        "print(x[0, 0, 0] * conv.causalConv1d.weight[0, 0, -1])\n",
        "print(conv.causalConv1d.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "dcd346f9-fcf6-4257-ac1d-8d029efad596",
      "metadata": {
        "id": "dcd346f9-fcf6-4257-ac1d-8d029efad596"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_sizes):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([nn.Sequential(CausalConv1d(cin, cout, k),\n",
        "                                                   nn.MaxPool1d(kernel_size=2),\n",
        "                                                   nn.ReLU())\n",
        "                                     for cin, cout, k in zip(in_channels, out_channels, kernel_sizes)])\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "72ac36eb-9fc6-4a84-a2d2-1b707670c974",
      "metadata": {
        "id": "72ac36eb-9fc6-4a84-a2d2-1b707670c974"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_sizes):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([nn.Sequential(nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                                   CausalConv1d(cin, cout, k),\n",
        "                                                   nn.ReLU())\n",
        "                                     for cin, cout, k in zip(in_channels, out_channels, kernel_sizes)])\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "ac17b874-3900-4f92-80ac-447c0e138284",
      "metadata": {
        "id": "ac17b874-3900-4f92-80ac-447c0e138284"
      },
      "outputs": [],
      "source": [
        "class TCN(nn.Module):\n",
        "    def __init__(self, vocab_size, d_emb, init_len, final_len, in_channels, out_channels, kernel_sizes, fc_dims=None):\n",
        "        super(TCN, self).__init__()\n",
        "        self.init_len = init_len\n",
        "        self.embedding = nn.Embedding(vocab_size, d_emb)\n",
        "        self.encoder = Encoder(in_channels, out_channels, kernel_sizes)\n",
        "        #self.decoder = Decoder(out_channels, in_channels, reversed(kernel_sizes))\n",
        "        self.fcs = None if fc_dims is None else nn.ModuleList([nn.Sequential(nn.Linear(in_features=fc_dim_in, out_features=fc_dim_out), nn.LeakyReLU()) for fc_dim_in, fc_dim_out in zip(fc_dims[:-1], fc_dims[1:])])\n",
        "        self.head = nn.Linear(in_features=final_len, out_features=vocab_size) if fc_dims is None else nn.Linear(in_features=fc_dims[-1], out_features=vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, _ = x.shape\n",
        "        x = self.embedding(x)\n",
        "        x = self.encoder(x.permute(0, 2, 1))\n",
        "        x = x.permute(0, 2, 1).reshape(N, -1)\n",
        "        if self.fcs is None: return self.head(x)\n",
        "        else:\n",
        "          for fc in self.fcs:\n",
        "            x = fc(x)\n",
        "          return self.head(x)\n",
        "\n",
        "    def sampling(self, start_chs, seq_len=100, device=\"cpu\"):\n",
        "        # Encode starting character\n",
        "        seq = encode(start_chs)\n",
        "        if len(seq) < self.init_len:\n",
        "            nb_start_dots = 0\n",
        "            while len(seq) < self.init_len:\n",
        "                seq = encode(\".\") + seq\n",
        "                nb_start_dots += 1\n",
        "        start_idx = 0\n",
        "        for t in range(seq_len):\n",
        "            x = torch.tensor(seq[start_idx:], device=device, dtype=torch.long).unsqueeze(0)\n",
        "            #print(x)\n",
        "\n",
        "            # Forward step\n",
        "            logits = self.forward(x)\n",
        "            #print(logits.shape)\n",
        "            probs = nn.Softmax(dim=-1)(logits).squeeze(0)\n",
        "\n",
        "            # Sample next token\n",
        "            next_ch = torch.multinomial(probs, num_samples=1).item()\n",
        "            seq.append(next_ch)\n",
        "            start_idx += 1\n",
        "\n",
        "        return decode(seq[nb_start_dots:])\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "26e25623-6ea4-41ea-b060-33b7dc04de2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26e25623-6ea4-41ea-b060-33b7dc04de2d",
        "outputId": "4fc0a151-1bce-4ea5-d22a-84cf374cb903"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TCN(\n",
              "  (embedding): Embedding(65, 32)\n",
              "  (encoder): Encoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): Sequential(\n",
              "        (0): CausalConv1d(\n",
              "          (causalConv1d): Conv1d(32, 64, kernel_size=(5,), stride=(1,))\n",
              "        )\n",
              "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): CausalConv1d(\n",
              "          (causalConv1d): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
              "        )\n",
              "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): CausalConv1d(\n",
              "          (causalConv1d): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
              "        )\n",
              "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): CausalConv1d(\n",
              "          (causalConv1d): Conv1d(256, 512, kernel_size=(3,), stride=(1,))\n",
              "        )\n",
              "        (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fcs): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (1): LeakyReLU(negative_slope=0.01)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (1): LeakyReLU(negative_slope=0.01)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
              "      (1): LeakyReLU(negative_slope=0.01)\n",
              "    )\n",
              "  )\n",
              "  (head): Linear(in_features=128, out_features=65, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "d_emb = 32 # Increased from 64\n",
        "nb_conv_layers = 4\n",
        "in_channels = [32, 64, 128, 256]\n",
        "out_channels = [64, 128, 256, 512]\n",
        "kernel_sizes = [5, 5, 3, 3]\n",
        "final_len = context_size\n",
        "for _ in range(len(out_channels)):\n",
        "    final_len = final_len // 2\n",
        "final_len *= out_channels[-1]\n",
        "fc_dims = [final_len, 512, 256, 128]\n",
        "model = TCN(vocab_size, d_emb, context_size, final_len, in_channels, out_channels, kernel_sizes, fc_dims)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "#print(\"Model created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "1559cc5a-1520-43a2-a3f2-37377b46bc38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1559cc5a-1520-43a2-a3f2-37377b46bc38",
        "outputId": "3fb4ac17-d0aa-4026-da92-b3284d53cafd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RichardRGVGFdfQqt\n"
          ]
        }
      ],
      "source": [
        "print(model.sampling(\"Richard\", 10, device))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "optimizer = optim.AdamW(params=model.parameters(), lr=lr, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.99)"
      ],
      "metadata": {
        "id": "xYekMzayBq7Q"
      },
      "id": "xYekMzayBq7Q",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "60469395-86cb-45eb-af27-72951cd6f05d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "60469395-86cb-45eb-af27-72951cd6f05d",
        "outputId": "983e6c01-d0f2-4e9b-88a6-45fddfd63c0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2179/2179 [00:47<00:00, 45.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss= 4.187439672987414\n",
            "Epoch 0\n",
            "Sampling...\n",
            "AdD-Pw-gcNemSlPDVQZ&QH3bXyBmRSPKD.C&Nblaqn$nsdVf:mtLiljVCkhWtfMxQBXmSej:YRq&WHEl;&FgxSPsADW.N-zrLcWkf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2179/2179 [00:46<00:00, 47.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, loss= 4.1744874242578645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2179/2179 [00:45<00:00, 47.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, loss= 4.147103744890232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2179/2179 [00:45<00:00, 47.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, loss= 4.068156126826769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2179/2179 [00:46<00:00, 47.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, loss= 3.8725483088167287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2179/2179 [00:45<00:00, 47.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, loss= 3.824574768898847\n",
            "Epoch 5\n",
            "Sampling...\n",
            "Aoh J n  DhMnal  a n p NO tjet ke eK sT- dvn fn H kld  vU  h oana  aph aO h e p,h Nib   n  nunw 3p wn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2179/2179 [00:45<00:00, 47.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, loss= 3.65852904702721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2179/2179 [00:46<00:00, 47.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, loss= 3.629333794363161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2179/2179 [00:46<00:00, 47.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, loss= 3.573397373157447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2179/2179 [00:46<00:00, 47.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, loss= 3.504501010366075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2179/2179 [00:45<00:00, 47.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, loss= 3.520072160482735\n",
            "Epoch 10\n",
            "Sampling...\n",
            "AZe  te tJtfa    tOth ieBehersoeep 3eejel uhiL\n",
            "Dir eiI ei phn qej,Dhhbhtt  hh n oU  \n",
            "vTseejeHta Kx eo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2179/2179 [00:46<00:00, 46.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, loss= 3.476538759242947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 521/2179 [00:11<00:35, 47.08it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3367898323.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3421883421.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "p = 0\n",
        "min_loss = 10000\n",
        "epochs = 50  # Increased from 20 to 50\n",
        "sampling_freq = epochs // 10\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "for epoch in range(epochs):\n",
        "    losses = []\n",
        "    for idx, (x, y) in enumerate(tqdm(train_loader)):\n",
        "        model.train()\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        y_logits = model(x)\n",
        "        optimizer.zero_grad()\n",
        "        #print(y.shape)\n",
        "        loss = loss_fn(y_logits.view(-1, vocab_size), y.view(-1))\n",
        "        loss.backward()\n",
        "        losses.append(loss.item())\n",
        "        if loss < min_loss:\n",
        "            min_loss = loss\n",
        "            best_model = model\n",
        "            best_epoch = epoch\n",
        "    print(f\"Epoch {epoch}, loss= {np.mean(np.array(losses))}\")\n",
        "\n",
        "    if epoch % sampling_freq == 0:\n",
        "        model.eval()\n",
        "        print(f\"Epoch {epoch}\")\n",
        "        print(\"Sampling...\")\n",
        "        print(model.sampling(\"A\", 100, device))\n",
        "    optimizer.step()\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c90ab412-2c9e-4d82-a1ec-4101f3162f6a",
      "metadata": {
        "id": "c90ab412-2c9e-4d82-a1ec-4101f3162f6a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}